import threading
import time
import streamlit as st
import os
from datetime import datetime
from PIL import Image
from main import MedGuideAI
from firebase_admin import firestore
import base64

# import text_to_speech
from speech_module.ffmpeg_decoding import AudioPlayer
from speech_module.tts_mp3_stream import tts_stream
from speech_module.test_streamlit_stt import speech_to_text
import speed_to_text as sp
from login import login, create_sample_users
import io
import PyPDF2
import re
import pdfplumber
from datetime import datetime

# Táº¡o user máº«u Firestore (chá»‰ cháº¡y 1 láº§n khi khá»Ÿi Ä‘á»™ng app)
if "users_initialized" not in st.session_state:
    create_sample_users()
    st.session_state["users_initialized"] = True

# Page configuration
st.set_page_config(page_title="MedGuide AI", page_icon="ğŸ¥", layout="centered")


# Define fragments
@st.fragment
def playback_controls(message_id: str, message_content: str):
    """Isolated fragment for managing playback controls for a single message."""
    # Get or create player reference in session state
    if "audio_players" not in st.session_state:
        st.session_state.audio_players = {}

    # Initialize player for this message if needed
    if message_id not in st.session_state.audio_players:
        st.session_state.audio_players[message_id] = None

    player = st.session_state.audio_players[message_id]
    is_playing = player is not None and player.is_playing()

    # Display appropriate button based on playback state
    if is_playing:
        if st.button("â¹ï¸", key=f"stop_{message_id}"):
            # Stop this specific playback
            if player:
                player.stop()
            # Clear player reference
            st.session_state.audio_players[message_id] = None
            st.rerun(scope="fragment")
            # The fragment will automatically rerun and show the Play button

        if (
            isinstance(player.playback_thread, threading.Thread)
            and player.playback_thread.is_alive()
        ):
            # time.sleep(0.1)
            # st.rerun(scope="fragment")
            pass
        else:
            st.session_state.audio_players[message_id] = None
        # time.sleep(3)
        # st.rerun(scope="fragment")

    else:
        if st.button("ğŸ”Š", key=f"play_{message_id}"):
            # First stop any active playback (enforce only one playback at a time)
            for msg_id, p in st.session_state.audio_players.items():
                if p is not None:
                    p.stop()
                    st.session_state.audio_players[msg_id] = None

            # Create new player for this message
            player = AudioPlayer()

            # Start playback in background thread
            def playback():
                player.play(tts_stream(message_content))

            t = threading.Thread(target=playback, daemon=True)
            st.session_state.audio_players[message_id] = player
            t.start()
            st.rerun(scope="fragment")


# Initialize AI
@st.cache_resource
def load_ai():
    return MedGuideAI()


def save_pdf_to_firestore(uploaded_pdf, target):
    db = firestore.client()
    uploaded_pdf.seek(0)  # reset con trá»
    with pdfplumber.open(io.BytesIO(uploaded_pdf.read())) as pdf:
        text = "\n".join([page.extract_text() or "" for page in pdf.pages])

    match = re.search(r"\b(\d{6})-(\d{12})\b", text)
    if match:
        date_str, user_id = match.groups()
        exam_date = datetime.strptime(date_str, "%y%m%d").date().isoformat()
    else:
        st.error("KhÃ´ng tÃ¬m tháº¥y mÃ£ bá»‡nh nhÃ¢n trong PDF")
        return

    # LÆ°u metadata vÃ o Firestore
    record_ref = db.collection(target).document()
    record_ref.set({
        # "fileUrl": file_url,
        "examDate": exam_date,
        "uploadedBy": "admin",
        "user_id": user_id,
        "parsedText": text,
        "createdAt": firestore.SERVER_TIMESTAMP
    })

    st.success(f"âœ… Upload thÃ nh cÃ´ng cho user {user_id}")


if "audio_record_bytes" not in st.session_state:
    st.session_state.audio_record_bytes = None


def main():
    # Header
    st.title("ğŸ¥ MedGuide AI")
    st.markdown("### TÆ° váº¥n y táº¿ thÃ´ng minh vá»›i AI")

    # Initialize
    ai = load_ai()

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "processing" not in st.session_state:
        st.session_state.processing = False

    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = []
    if "patient_context" not in st.session_state:
        st.session_state.patient_context = {
            "medical_history": [],
            "medications": [],
            "allergies": [],
            "symptoms_timeline": [],
        }
    if "processing_image" not in st.session_state:
        st.session_state.processing_image = False
    if "temp_image" not in st.session_state:
        st.session_state.temp_image = None

    # Welcome message - show full intro on first visit, short version afterwards
    if not st.session_state.messages:
        st.info(
            """
            ğŸ‘‹ **ChÃ o má»«ng Ä‘áº¿n vá»›i MedGuide AI!**
           
            ğŸ—£ï¸ **Báº¡n cÃ³ thá»ƒ:**
            - Há»i vá» triá»‡u chá»©ng, thuá»‘c, xÃ©t nghiá»‡m
            - Upload hÃ¬nh áº£nh Ä‘Æ¡n thuá»‘c hoáº·c káº¿t quáº£ xÃ©t nghiá»‡m Ä‘á»ƒ phÃ¢n tÃ­ch
            - TrÃ² chuyá»‡n liÃªn tá»¥c vá»›i AI Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t
           
            ğŸ’¡ **CÃ¡ch sá»­ dá»¥ng nhanh:**
            - Nháº­p cÃ¢u há»i vÃ  nháº¥n Enter Ä‘á»ƒ gá»­i
            - DÃ¹ng nÃºt ğŸ“· Ä‘á»ƒ gá»­i hÃ¬nh áº£nh y táº¿
            - Sá»­ dá»¥ng cÃ¡c cÃ¢u há»i máº«u bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u
            """
        )
    else:
        st.info("### TÆ° váº¥n y táº¿ thÃ´ng minh vá»›i AI")

    # Display chat history with container for better scrolling
    if st.session_state.messages:
        st.markdown("### ğŸ’¬ Cuá»™c trÃ² chuyá»‡n")

        # Create container for chat messages
        chat_container = st.container()
        with chat_container:
            for message_index, message in enumerate(st.session_state.messages):
                with st.chat_message(message["role"]):
                    st.write(message["content"])

                    # Show image if exists
                    if "image" in message:
                        st.image(message["image"], width=300)

                    # Show classification info
                    if message["role"] == "assistant" and "topic" in message:
                        topic_icons = {
                            "symptoms": "ğŸ©º",
                            "drug_groups": "ğŸ’Š",
                            "lab_results": "ğŸ§ª",
                            "unknown": "â“",
                        }
                        # st.caption(f"{topic_icons.get(message['topic'], 'â“')} {message['topic']}")

                    # Add audio player for assistant messages
                    if message["role"] == "assistant":
                        playback_controls(str(message_index), message["content"])

    # Show processing indicators right after chat history
    if st.session_state.get("processing", False):
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤– Äang xá»­ lÃ½..."):
                st.write("ğŸ¤– Äang xá»­ lÃ½ cÃ¢u há»i cá»§a báº¡n...")

    if st.session_state.get("processing_image", False):
        with st.chat_message("assistant"):
            with st.spinner("ğŸ” Äang phÃ¢n tÃ­ch hÃ¬nh áº£nh..."):
                st.write("ğŸ” Äang phÃ¢n tÃ­ch hÃ¬nh áº£nh y táº¿...")

    # Input section at bottom
    st.markdown("---")

    # Combined input area with image upload
    col1, col2 = st.columns([6, 4])
    audio_bytes_ = st.audio_input("Speak something...", key="audio_recorder")
    if audio_bytes_:
        st.audio(audio_bytes_)
        print(audio_bytes_.size)
        st.session_state.audio_record_bytes = audio_bytes_
    if st.button("Send"):
        if st.session_state.audio_record_bytes is not None:

            audio_text = sp.speech_to_text_raw_bytes(
                st.session_state.audio_record_bytes
            )

            audio_content = audio_text
            print(audio_content)
            st.session_state.audio_record_bytes = None

            st.session_state.messages.append({"role": "user", "content": audio_content})

            st.session_state.processing = True

    with col1:
        # Chat input
        user_text = st.chat_input(placeholder="Nháº­p cÃ¢u há»i y táº¿... (Enter Ä‘á»ƒ gá»­i)")
        text_submit = bool(user_text)

    with col2:
        # Use dynamic key to clear file uploader after submit
        upload_key = f"file_upload_{st.session_state.get('upload_counter', 0)}"
        uploaded_file = st.file_uploader(
            "ğŸ“·",
            type=["jpg", "jpeg", "png"],
            help="Gá»­i hÃ¬nh áº£nh y táº¿ (Ä‘Æ¡n thuá»‘c, xÃ©t nghiá»‡m...)",
            key=upload_key,
            label_visibility="collapsed",
        )

    # Show image preview when uploaded
    if uploaded_file and not st.session_state.get("processing_image", False):
        col1, col2 = st.columns([1, 3])

        with col1:
            st.image(uploaded_file, width=120, caption="HÃ¬nh áº£nh Ä‘Ã£ chá»n")

        with col2:
            st.info("ğŸ“· HÃ¬nh áº£nh Ä‘Ã£ chá»n! Nháº­p cÃ¢u há»i hoáº·c nháº¥n Enter Ä‘á»ƒ phÃ¢n tÃ­ch.")

    # Process text input (with or without image)
    if text_submit and (user_text.strip() or uploaded_file):
        # Determine content and processing type
        if uploaded_file:
            # Image with optional text
            user_content = (
                user_text.strip() if user_text.strip() else "PhÃ¢n tÃ­ch hÃ¬nh áº£nh nÃ y"
            )
            st.session_state.messages.append(
                {"role": "user", "content": user_content, "image": uploaded_file}
            )
            st.session_state.processing_image = True
            st.session_state.temp_image = uploaded_file
        else:
            # Text only
            st.session_state.messages.append({"role": "user", "content": user_text})
            st.session_state.processing = True
        st.rerun()

    # Handle processing state (background processing)
    if st.session_state.get("processing", False):
        # Get the last user message
        last_user_msg = None
        for msg in reversed(st.session_state.messages):
            if msg["role"] == "user":
                last_user_msg = msg["content"]
                break

        if last_user_msg:
            # Process with AI (no UI here, just processing)
            print("<duypv10 log> last_user_msg: ", last_user_msg)
            result = ai.process_user_query(last_user_msg, st.session_state['user']['latest_test_result'])

            if "error" in result:
                response = f"âŒ Lá»—i: {result['error']}"
                topic = "error"
            else:
                response = result.get("ai_response", "KhÃ´ng cÃ³ pháº£n há»“i")
                topic = result.get("topic_classified", "unknown")

                # Generate audio
                # audio_bytes = text_to_speech.run_audio(response)

            # Add AI response to messages
            st.session_state.messages.append(
                {
                    "role": "assistant",
                    "content": response,
                    "topic": topic,
                    # "audio": audio_bytes
                }
            )

            # Clear processing state
            st.session_state.processing = False
            st.rerun()

    # Clear file uploader after processing
    if (text_submit and uploaded_file) or st.session_state.get(
        "processing_image", False
    ):
        if "upload_counter" not in st.session_state:
            st.session_state.upload_counter = 0
        st.session_state.upload_counter += 1

    # Handle image processing state (background processing)
    if st.session_state.get("processing_image", False):
        # Process with AI (no UI here, just processing)
        temp_image = st.session_state.temp_image
        temp_image.seek(0)
        response = ai.analyze_medical_image(temp_image, "general")

        # Generate audio
        # audio_bytes = text_to_speech.run_audio(response)

        # Add AI response to messages
        st.session_state.messages.append(
            {
                "role": "assistant",
                "content": response,
                "topic": "image_analysis",
                # "audio": audio_bytes
            }
        )

        # Clear processing state and file uploader
        st.session_state.processing_image = False
        st.session_state.temp_image = None
        if "upload_counter" not in st.session_state:
            st.session_state.upload_counter = 0
        st.session_state.upload_counter += 1

        st.rerun()

    # Sidebar: ÄÄƒng nháº­p vÃ  phÃ¢n quyá»n
    with st.sidebar:
        st.header("ğŸ”‘ ÄÄƒng nháº­p")
        if "user" not in st.session_state:
            username = st.text_input("Username hoáº·c Email", key="login_username")
            password = st.text_input("Password", type="password", key="login_password")
            login_btn = st.button("ÄÄƒng nháº­p", key="login_btn")
            if login_btn:
                user = login(username, password)
                if user:
                    st.session_state["user"] = user
                    st.success(f"ÄÄƒng nháº­p thÃ nh cÃ´ng! Role: {user['role']}")
                    st.rerun()
                else:
                    st.error("ÄÄƒng nháº­p tháº¥t báº¡i! Kiá»ƒm tra láº¡i thÃ´ng tin.")
        else:
            st.info(
                f"Xin chÃ o, {st.session_state['user']['username']} ({st.session_state['user']['role']})"
            )
            logout_btn = st.button("ÄÄƒng xuáº¥t", key="logout_btn")
            if logout_btn:
                del st.session_state["user"]
                st.success("ÄÃ£ Ä‘Äƒng xuáº¥t!")
                st.rerun()
            if st.session_state["user"]["role"] == "admin":
                st.subheader("ğŸ“„ Upload káº¿t quáº£ khÃ¡m bá»‡nh (PDF)")
                uploaded_pdf = st.file_uploader(
                    "Chá»n file PDF káº¿t quáº£ khÃ¡m bá»‡nh", type=["pdf"], key="pdf_uploader"
                )
                if uploaded_pdf:
                    st.success(f"ÄÃ£ upload file: {uploaded_pdf.name}")
                    if st.button("LÆ°u vÃ o Firestore", key="save_pdf_btn"):
                        save_pdf_to_firestore(
                            st.session_state["user"]["username"], uploaded_pdf
                        )
                        st.success("ÄÃ£ lÆ°u file PDF vÃ o Firestore!")

    # File upload section for Pinecone DB
    with st.sidebar:
        st.markdown("### ğŸ“ ThÃªm tÃ i liá»‡u y táº¿")

        # Collection selection
        collection_choice = st.selectbox(
            "Chá»n loáº¡i tÃ i liá»‡u:",
            ["TÃ i liá»‡u thuá»‘c ná»™i bá»™", "ÄÆ¡n thuá»‘c cá»§a bá»‡nh nhÃ¢n", "KQXN cá»§a bá»‡nh nhÃ¢n"],
        )

        # File uploader
        doc_file = st.file_uploader(
            "Upload file (.txt, .pdf):",
            type=["txt", "pdf"],
            help="TÃ i liá»‡u y táº¿ Ä‘á»ƒ bá»• sung cÆ¡ sá»Ÿ dá»¯ liá»‡u",
        )

        if doc_file and st.button("ğŸ“¤ ThÃªm vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u", use_container_width=True):
            with st.spinner("Äang xá»­ lÃ½ tÃ i liá»‡u..."):
                try:
                    content = None
                    target_collection = None

                    collection_map = {
                        "TaÌ€i liÃªÌ£u thuÃ´Ìc nÃ´Ì£i bÃ´Ì£": "drug_groups",
                        "ÄÆ¡n thuá»‘c cá»§a bá»‡nh nhÃ¢n": "patient_prescriptions",
                        "KQXN cá»§a bá»‡nh nhÃ¢n": "patient_test_results"
                    }
                    target_collection = collection_map[collection_choice]

                    if collection_choice == "TaÌ€i liÃªÌ£u thuÃ´Ìc nÃ´Ì£i bÃ´Ì£":
                        if doc_file.type == "text/plain":
                            content = str(doc_file.read(), "utf-8")
                            # Náº¿u lÃ  tÃ i liá»‡u thuá»‘c ná»™i bá»™ vÃ  cÃ³ ná»™i dung thÃ¬ upload luÃ´n
                            if content:
                                additions = ai.pinecone_db.add_to_specific_collection(
                                    content, doc_file.name, target_collection
                                )

                                if "error" in additions:
                                    st.error(f"âŒ Lá»—i khi thÃªm dá»¯ liá»‡u: {additions['error']}")
                                    if "No Pinecone connection" in additions["error"]:
                                        st.warning("âš ï¸ Vui lÃ²ng táº¡o file .env vá»›i PINECONE_API_KEY cá»§a báº¡n")
                                elif sum(additions.values()) == 0:
                                    st.warning("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c thÃªm vÃ o. Kiá»ƒm tra ná»™i dung file vÃ  káº¿t ná»‘i Pinecone.")
                                else:
                                    st.success(f"âœ… Success")

                                stats = ai.pinecone_db.get_collection_stats()
                        else:
                            st.error("Hiá»‡n táº¡i chá»‰ há»— trá»£ file .txt cho TÃ i liá»‡u thuá»‘c ná»™i bá»™")

                    # Vá»›i ÄÆ¡n thuá»‘c hoáº·c KQXN -> Ä‘á»ƒ báº¡n tá»± xá»­ lÃ½ PDF á»Ÿ bÆ°á»›c khÃ¡c
                    elif collection_choice in ["ÄÆ¡n thuá»‘c cá»§a bá»‡nh nhÃ¢n", "KQXN cá»§a bá»‡nh nhÃ¢n"]:
                        if doc_file.type == "application/pdf":
                            save_pdf_to_firestore(doc_file, target_collection)
                        else:
                            st.error("Chá»‰ há»— trá»£ file .pdf cho loáº¡i tÃ i liá»‡u nÃ y")


                except Exception as e:
                    st.error(f"âŒ Lá»—i: {str(e)}")


        st.markdown("---")

    # # Quick actions - always show for easy access
    # st.markdown("### ğŸš€ CÃ¢u há»i máº«u:")
    # col1, col2, col3 = st.columns(3)

    # with col1:
    #     if st.button("ğŸ’Š Há»i vá» thuá»‘c"):
    #         st.session_state.messages.append({
    #             "role": "user",
    #             "content": "Paracetamol cÃ³ tÃ¡c dá»¥ng gÃ¬?"
    #         })
    #         st.rerun()

    # with col2:
    #     if st.button("ğŸ§ª Há»i vá» xÃ©t nghiá»‡m"):
    #         st.session_state.messages.append({
    #             "role": "user",
    #             "content": "Glucose 150 mg/dL cÃ³ cao khÃ´ng?"
    #         })
    #         st.rerun()

    # with col3:
    #     if st.button("ğŸ©º Há»i vá» triá»‡u chá»©ng"):
    #         st.session_state.messages.append({
    #             "role": "user",
    #             "content": "TÃ´i bá»‹ Ä‘au Ä‘áº§u vÃ  chÃ³ng máº·t"
    #         })
    #         st.rerun()

    # Clear chat
    if st.session_state.messages:
        if st.button("ğŸ—‘ï¸ XÃ³a cuá»™c trÃ² chuyá»‡n", type="secondary"):
            st.session_state.messages = []
            st.rerun()

    # Footer
    st.markdown("---")
    st.caption("âš ï¸ ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o, hÃ£y tham kháº£o bÃ¡c sÄ© chuyÃªn khoa")


if __name__ == "__main__":
    main()
