import os
from dotenv import load_dotenv
from langchain_core.messages import BaseMessage
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
import easyocr
from PIL import Image
import cv2
import numpy as np
import firebase_admin
from firebase_admin import credentials, firestore
from datetime import datetime
import streamlit as st

def init_firebase():
    if not firebase_admin._apps:  # Náº¿u chÆ°a cÃ³ app nÃ o Ä‘Æ°á»£c khá»Ÿi táº¡o
        firebase_config = dict(st.secrets["firebase"])
        cred = credentials.Certificate(firebase_config)
        firebase_admin.initialize_app(cred)
        print("Firebase initialized.")
    else:
        print("Firebase already initialized.")


# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Gá»i hÃ m khá»Ÿi táº¡o
init_firebase()
db = firestore.client()

llm = ChatOpenAI(
    base_url=st.secrets["OPENAI_ENDPOINT"],
    api_key=st.secrets["OPENAI_API_KEY"],
    model=st.secrets["OPENAI_MODEL"],
    temperature=0
)

# OCR tiáº¿ng Viá»‡t
def image_to_text(uploaded_file):
    image = Image.open(uploaded_file)
    image_np = np.array(image)
    if image_np.shape[2] == 4:
        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)
    reader = easyocr.Reader(['vi'], gpu=False)
    results = reader.readtext(image_np)
    texts = [{"text": text, "confidence": conf} for _, text, conf in results]
    text_for_prompt = "\n".join(
        f"{item['text']} (Ä‘á»™ tin cáº­y: {item['confidence']:.2f})"
        for item in texts
    )
    return text_for_prompt

# Prompt phÃ¢n loáº¡i
classification_prompt = PromptTemplate(
    input_variables=["text"],
    template="""
PhÃ¢n loáº¡i tÃ i liá»‡u sau thÃ nh 1 trong cÃ¡c loáº¡i: Ä‘Æ¡n thuá»‘c, káº¿t quáº£ xÃ©t nghiá»‡m, unknown. 
Ná»™i dung dÆ°á»›i Ä‘Ã¢y lÃ  káº¿t quáº£ OCR tá»« áº£nh, má»—i dÃ²ng gá»“m ná»™i dung vÃ  Ä‘á»™ tin cáº­y:
{text}
Chá»‰ tráº£ vá» duy nháº¥t tÃªn loáº¡i.
"""
)

def classify_doc_type(text: str) -> str:
    try:
        chain = classification_prompt | llm
        result = chain.invoke({"text": text})
        print("PhÃ¢n loáº¡i LLM tráº£ vá»:", result)
        return result.content.strip().lower()
    except Exception as e:
        print("Lá»—i khi gá»i OpenAI:", e)
        return "unknown"

def analyze_medicine_with_knowledge(ocr_text: str, latest_prescription, latest_test_result) -> BaseMessage:
    """
    DÃ¹ng OpenAI Ä‘á»ƒ tÃ¬m hiá»ƒu thÃ´ng tin thuá»‘c tá»« ná»™i dung OCR cá»§a Ä‘Æ¡n thuá»‘c.
    """
    knowledge_prompt = PromptTemplate(
        input_variables=["ocr_text", "latest_prescription", "latest_test_result"],
        template="""
        Báº¡n lÃ  bÃ¡c sÄ© y khoa.
        
        DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung OCR tá»« áº£nh Ä‘Æ¡n thuá»‘c mÆ¡Ìi nhÃ¢Ìt maÌ€ bÃªÌ£nh nhÃ¢n upload (cÃ³ thá»ƒ chá»©a nhiá»u tÃªn thuá»‘c, liá»u lÆ°á»£ng, cÃ¡ch dÃ¹ng):
        
        {ocr_text}
        
        DÆ°Æ¡Ìi Ä‘Ã¢y laÌ€ Ä‘Æ¡n thuÃ´Ìc gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n:
        
        {latest_prescription}
        
        DÆ°Æ¡Ìi Ä‘Ã¢y laÌ€ kÃªÌt quaÌ‰ xeÌt nghiÃªÌ£m gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n:
        
        {latest_test_result}
        
        YÃªu cÃ¢Ì€u:
        1. DÆ°Ì£a theo nÃ´Ì£i dung OCR tÆ°Ì€ aÌ‰nh Ä‘Æ¡n thuÃ´Ìc mÆ¡Ìi nhÃ¢Ìt maÌ€ bÃªÌ£nh nhÃ¢n vÆ°Ì€a upload, traÌ‰ vÃªÌ€ tÃªn thuÃ´Ìc, liÃªÌ€u lÆ°Æ¡Ì£ng, caÌch duÌ€ng, taÌc duÌ£ng phuÌ£
        2. So saÌnh ná»™i dung OCR tá»« áº£nh Ä‘Æ¡n thuá»‘c mÆ¡Ìi nhÃ¢Ìt maÌ€ bÃªÌ£nh nhÃ¢n upload vÆ¡Ìi Ä‘Æ¡n thuÃ´Ìc gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n, kiÃªÌ‰m tra tÆ°Æ¡ng taÌc thuÃ´Ìc coÌ thÃªÌ‰ xaÌ‰y ra giÆ°Ìƒa 2 Ä‘Æ¡n thuÃ´Ìc.
        3. DÆ°Ì£a vaÌ€o kÃªÌt quaÌ‰ xeÌt nghiÃªÌ£m gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n, kiÃªÌ‰m tra caÌc thuÃ´Ìc trong ná»™i dung OCR tá»« áº£nh Ä‘Æ¡n thuá»‘c mÆ¡Ìi nhÃ¢Ìt maÌ€ bÃªÌ£nh nhÃ¢n upload coÌ thÃªÌ‰ gÃ¢y aÌ‰nh hÆ°Æ¡Ì‰ng giÌ€ khÃ´ng
        """
    )


    chain = knowledge_prompt | llm
    result = chain.invoke({"ocr_text": ocr_text, "latest_prescription": latest_prescription, "latest_test_result": latest_test_result})
    return result


def analyze_lab_with_knowledge(lab_text: str, latest_prescription, latest_test_result) -> BaseMessage:
    """
    DÃ¹ng OpenAI Ä‘á»ƒ giáº£i thÃ­ch Ã½ nghÄ©a cho danh sÃ¡ch káº¿t quáº£ xÃ©t nghiá»‡m.
    lab_text: ná»™i dung OCR cá»§a báº£ng káº¿t quáº£ xÃ©t nghiá»‡m
    """
    knowledge_prompt = PromptTemplate(
        input_variables=["lab_text", "latest_prescription", "latest_test_result"],
        template="""
            Báº¡n lÃ  chuyÃªn gia xÃ©t nghiá»‡m y khoa.
            
            DÆ°Æ¡Ìi Ä‘Ã¢y laÌ€ ná»™i dung OCR tá»« báº£ng káº¿t quáº£ xÃ©t nghiá»‡m y táº¿:
            
            {lab_text}
            
            DÆ°Æ¡Ìi Ä‘Ã¢y laÌ€ Ä‘Æ¡n thuÃ´Ìc gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n:
                
            {latest_prescription}
                
            DÆ°Æ¡Ìi Ä‘Ã¢y laÌ€ kÃªÌt quaÌ‰ xeÌt nghiÃªÌ£m gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n:
                
            {latest_test_result}
                
            YÃªu cÃ¢Ì€u:
            1. DÆ°Ì£a theo nÃ´Ì£i dung OCR tÆ°Ì€ báº£ng káº¿t quáº£ xÃ©t nghiá»‡m y tÃªÌ, phÃ¢n tiÌch vaÌ€ giaÌ‰i thiÌch vÃªÌ€ tÃ¢Ìt caÌ‰ caÌc chiÌ‰ sÃ´Ì.
            2. So saÌnh ná»™i dung OCR tÆ°Ì€ báº£ng káº¿t quáº£ xÃ©t nghiá»‡m y tÃªÌ vÆ¡Ìi kÃªÌt quaÌ‰ xeÌt nghiÃªÌ£m gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n, phÃ¢n tiÌch vaÌ€ nhÃ¢Ì£n xeÌt sÆ°Ì£ thay Ä‘Ã´Ì‰i giÆ°Ìƒa hai lÃ¢Ì€n.
            3. DÆ°Ì£a vaÌ€o Ä‘Æ¡n thuÃ´Ìc gÃ¢Ì€n nhÃ¢Ìt cuÌ‰a bÃªÌ£nh nhÃ¢n trong kho dÆ°Ìƒ liÃªÌ£u bÃªÌ£nh viÃªÌ£n, kiÃªÌ‰m tra xem coÌ loaÌ£i thuÃ´Ìc naÌ€o cÃ¢Ì€n chuÌ yÌ hoÄƒÌ£c coÌ thÃªÌ‰ gÃ¢y aÌ‰nh hÆ°Æ¡Ì‰ng xÃ¢Ìu Ä‘ÃªÌn bÃªÌ£nh nhÃ¢n khÃ´ng?
            """
    )


    chain = knowledge_prompt | llm
    return chain.invoke({"lab_text": lab_text, "latest_prescription": latest_prescription, "latest_test_result": latest_test_result})

def process_image_pipeline(image_path: str, latest_prescription, latest_test_result):
    print("ğŸ” Báº¯t Ä‘áº§u OCR...")
    text = image_to_text(image_path)
    print("ğŸ“„ Káº¿t quáº£ OCR:\n", text)

    print("ğŸ“‚ Äang phÃ¢n loáº¡i tÃ i liá»‡u...")
    doc_type = classify_doc_type(text)
    print("ğŸ“Œ Loáº¡i tÃ i liá»‡u:", doc_type)

    item = None
    if doc_type == "Ä‘Æ¡n thuá»‘c":
        item = analyze_medicine_with_knowledge(text, latest_prescription, latest_test_result)
        print("item1", item.content)
    elif doc_type == "káº¿t quáº£ xÃ©t nghiá»‡m":
        item = analyze_lab_with_knowledge(text, latest_prescription, latest_test_result)
        print('item2', item.content)

    return {
        "doc_type": doc_type,
        "data": item.content,
    }
