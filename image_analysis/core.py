import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from image_analysis.schemas import MedicineList, LabList
import easyocr
from PIL import Image
import cv2
import numpy as np
import firebase_admin
from firebase_admin import credentials, firestore
from datetime import datetime

def init_firebase():
    if not firebase_admin._apps:  # Náº¿u chÆ°a cÃ³ app nÃ o Ä‘Æ°á»£c khá»Ÿi táº¡o
        cred = credentials.Certificate("baymax-a7a0d-firebase-adminsdk-fbsvc-f00628f505.json")
        firebase_admin.initialize_app(cred)
        print("Firebase initialized.")
    else:
        print("Firebase already initialized.")


# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Gá»i hÃ m khá»Ÿi táº¡o
init_firebase()
db = firestore.client()

llm = ChatOpenAI(
    base_url=os.getenv("OPENAI_ENDPOINT"),
    api_key=os.getenv("OPENAI_API_KEY"),
    model=os.getenv("OPENAI_MODEL", "text-embedding-3-small"),
)

# OCR tiáº¿ng Viá»‡t
def image_to_text(uploaded_file):
    image = Image.open(uploaded_file)
    image_np = np.array(image)
    if image_np.shape[2] == 4:
        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)
    reader = easyocr.Reader(['vi'], gpu=False)
    results = reader.readtext(image_np)
    texts = [{"text": text, "confidence": conf} for _, text, conf in results]
    text_for_prompt = "\n".join(
        f"{item['text']} (Ä‘á»™ tin cáº­y: {item['confidence']:.2f})"
        for item in texts
    )
    return text_for_prompt

# Prompt phÃ¢n loáº¡i
classification_prompt = PromptTemplate(
    input_variables=["text"],
    template="""
PhÃ¢n loáº¡i tÃ i liá»‡u sau thÃ nh 1 trong cÃ¡c loáº¡i: Ä‘Æ¡n thuá»‘c, káº¿t quáº£ xÃ©t nghiá»‡m, unknown. 
Ná»™i dung dÆ°á»›i Ä‘Ã¢y lÃ  káº¿t quáº£ OCR tá»« áº£nh, má»—i dÃ²ng gá»“m ná»™i dung vÃ  Ä‘á»™ tin cáº­y:
{text}
Chá»‰ tráº£ vá» duy nháº¥t tÃªn loáº¡i.
"""
)

def classify_doc_type(text: str) -> str:
    try:
        chain = classification_prompt | llm
        result = chain.invoke({"text": text})
        print("PhÃ¢n loáº¡i LLM tráº£ vá»:", result)
        return result.content.strip().lower()
    except Exception as e:
        print("Lá»—i khi gá»i OpenAI:", e)
        return "unknown"

def analyze_medicine_with_knowledge(ocr_text: str) -> list:
    """
    DÃ¹ng OpenAI Ä‘á»ƒ tÃ¬m hiá»ƒu thÃ´ng tin thuá»‘c tá»« ná»™i dung OCR cá»§a Ä‘Æ¡n thuá»‘c.
    """
    knowledge_prompt = PromptTemplate(
        input_variables=["ocr_text"],
        template="""
    Báº¡n lÃ  bÃ¡c sÄ© y khoa.
    
    DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung OCR tá»« áº£nh Ä‘Æ¡n thuá»‘c (cÃ³ thá»ƒ chá»©a nhiá»u tÃªn thuá»‘c, liá»u lÆ°á»£ng, cÃ¡ch dÃ¹ng):
    
    {ocr_text}
    
    YÃªu cáº§u:
    1. XÃ¡c Ä‘á»‹nh táº¥t cáº£ cÃ¡c thuá»‘c cÃ³ trong ná»™i dung trÃªn.
    2. XaÌc Ä‘iÌ£nh ngÃ y thÃ¡ng xuáº¥t hiá»‡n trong nÃ´Ì£i dung OCR. Äáº¶C BIá»†T chÃº Ã½ láº¥y Ä‘Ãºng ngÃ y kÃª Ä‘Æ¡n hoáº·c ngÃ y xuáº¥t hiá»‡n cuá»‘i cÃ¹ng trÃªn tÃ i liá»‡u (khÃ´ng láº¥y cÃ¡c ngÃ y khÃ¡c nhÆ° ngÃ y sinh, ngÃ y háº¹n tÃ¡i khÃ¡m). Äáº£m báº£o chá»‰ láº¥y Ä‘Ãºng má»™t ngÃ y duy nháº¥t lÃ  ngÃ y kÃª Ä‘Æ¡n hoáº·c ngÃ y xuáº¥t hiá»‡n cuá»‘i Ä‘Æ¡n thuá»‘c.
        - Náº¿u tÃ i liá»‡u cÃ³ ngÃ y kÃª Ä‘Æ¡n hoáº·c ngÃ y xuáº¥t hiá»‡n cuá»‘i cÃ¹ng trÃªn tÃ i liá»‡u â†’ trÃ­ch xuáº¥t Ä‘Ãºng ngÃ y Ä‘Ã³.
        - Format ngÃ y Ä‘Ãºng chuáº©n ISO datetime, vÃ­ dá»¥: "2025-08-12T00:00:00".
        - Náº¿u nhiá»u ngÃ y xuáº¥t hiá»‡n: Æ¯u tiÃªn ngÃ y gáº§n nháº¥t vá»›i cÃ¡c tá»« khoÃ¡ nhÆ° â€œngÃ y kÃª Ä‘Æ¡nâ€, â€œngÃ yâ€, â€œngÃ y cáº¥pâ€, "date", "prescription date", "issued date", hoáº·c ngÃ y á»Ÿ cuá»‘i tÃ i liá»‡u.
        - Náº¿u khÃ´ng cÃ³ ngÃ y nÃ o Ä‘Æ°á»£c ghi rÃµ rÃ ng â†’ dÃ¹ng ngÃ y, giá» hiá»‡n táº¡i á»Ÿ Viá»‡t Nam, format ISO datetime, vÃ­ dá»¥: "2025-08-12T00:00:00".
        - Tuyá»‡t Ä‘á»‘i khÃ´ng láº¥y ngÃ y sinh, ngÃ y tÃ¡i khÃ¡m, hoáº·c cÃ¡c ngÃ y khÃ´ng liÃªn quan.
    
    3. Vá»›i má»—i thuá»‘c, cung cáº¥p thÃ´ng tin theo schema JSON sau:
       - medicine_name: giá»¯ nguyÃªn tÃªn thuá»‘c (bao gá»“m cáº£ hÃ m lÆ°á»£ng náº¿u cÃ³)
       - effect: tÃ¡c dá»¥ng chÃ­nh cá»§a thuá»‘c
       - side_effects: tÃ¡c dá»¥ng phá»¥ hoáº·c lÆ°u Ã½ khi dÃ¹ng
       - interaction_with_history: tÆ°Æ¡ng tÃ¡c vá»›i tiá»n sá»­ bá»‡nh cá»§a bá»‡nh nhÃ¢n
    
    4. Tiá»n sá»­ bá»‡nh nhÃ¢n: bÃ©o phÃ¬
    
    5. Tráº£ vá» JSON duy nháº¥t theo schema:
    {{
        "document_date": "YYYY-MM-DDTHH:MM:SS",  // ngÃ y tÃ i liá»‡u, náº¿u khÃ´ng tÃ¬m tháº¥y thÃ¬ dÃ¹ng ngÃ y hiá»‡n táº¡i á»Ÿ Viá»‡t Nam
        "medicines": [
            {{
                "medicine_name": "...",
                "effect": "...",
                "side_effects": "...",
                "interaction_with_history": "..."
            }}
        ]
    }}
    
    6. KhÃ´ng kÃ¨m báº¥t ká»³ giáº£i thÃ­ch hoáº·c vÄƒn báº£n ngoÃ i JSON. Chá»‰ tráº£ vá» JSON thuáº§n.
    """
    )


    chain = knowledge_prompt | llm.with_structured_output(MedicineList)
    result = chain.invoke({"ocr_text": ocr_text})
    return result  # list[MedicineItem]


def analyze_lab_with_knowledge(lab_text: str) -> list:
    """
    DÃ¹ng OpenAI Ä‘á»ƒ giáº£i thÃ­ch Ã½ nghÄ©a cho danh sÃ¡ch káº¿t quáº£ xÃ©t nghiá»‡m.
    lab_text: ná»™i dung OCR cá»§a báº£ng káº¿t quáº£ xÃ©t nghiá»‡m
    """
    knowledge_prompt = PromptTemplate(
        input_variables=["lab_text"],
        template="""
Báº¡n lÃ  chuyÃªn gia xÃ©t nghiá»‡m y khoa.

Ná»™i dung OCR tá»« báº£ng káº¿t quáº£ xÃ©t nghiá»‡m y táº¿:

{lab_text}

Tiá»n sá»­ bá»‡nh nhÃ¢n: bÃ©o phÃ¬

YÃªu cáº§u:

1.  Náº¿u gáº·p trÆ°á»ng `document_date`, báº¡n **luÃ´n** gÃ¡n giÃ¡ trá»‹ lÃ  ngÃ y vÃ  giá» hiá»‡n táº¡i theo Ä‘á»‹nh dáº¡ng ISO 8601 (`YYYY-MM-DDTHH:MM:SS`) thay vÃ¬ láº¥y tá»« ná»™i dung OCR.
2. XÃ¡c Ä‘á»‹nh tá»«ng xÃ©t nghiá»‡m riÃªng biá»‡t:
    - Má»—i xÃ©t nghiá»‡m gá»“m: test_name, value, unit, range.
    - Náº¿u thiáº¿u hoáº·c khÃ´ng há»£p lÃ½ (kÃ½ tá»± láº¡, Ä‘Æ¡n vá»‹ sai, khoáº£ng khÃ´ng logic):
        + Ghi "ChÆ°a rÃµ" cho trÆ°á»ng sai/thiáº¿u
        + evaluation = "ChÆ°a rÃµ"
        + explanation = "KhÃ´ng Ä‘á»§ thÃ´ng tin Ä‘á»ƒ phÃ¢n tÃ­ch"
    - Náº¿u Ä‘áº§y Ä‘á»§ vÃ  há»£p lÃ½ â†’ so sÃ¡nh value vá»›i range:
        + evaluation = "á»”n" náº¿u trong khoáº£ng
        + evaluation = "KhÃ´ng á»•n" náº¿u ngoÃ i khoáº£ng
        + explanation = MÃ´ táº£ tÃ¡c Ä‘á»™ng Ä‘áº¿n sá»©c khá»e bá»‡nh nhÃ¢n (xÃ©t cáº£ tiá»n sá»­ bá»‡nh nhÃ¢n).

3. Tráº£ vá» JSON Ä‘Ãºng schema:
{{"document_date": "YYYY-MM-DDTHH:MM:SS",
  "lab": [
      {{"test_name": "...",
       "value": "...",
       "unit": "...",
       "range": "...",
       "evaluation": "...",
       "explanation": "..."}}
  ]
}}

4. Quy táº¯c bá»• sung:
    - Náº¿u khÃ´ng match Ä‘Æ°á»£c regex ngÃ y há»£p lá»‡ â†’ luÃ´n tráº£ vá» ngÃ y hiá»‡n táº¡i VN.
    - Tuyá»‡t Ä‘á»‘i khÃ´ng tráº£ vá» báº¥t ká»³ ngÃ y nÃ o trong nÄƒm 2023 náº¿u khÃ´ng xuáº¥t hiá»‡n trong OCR.
    - Chá»‰ tráº£ vá» JSON thuáº§n, khÃ´ng giáº£i thÃ­ch bÃªn ngoÃ i.
"""
    )


    chain = knowledge_prompt | llm.with_structured_output(LabList)
    return chain.invoke({"lab_text": lab_text})

def normalize_test_name(name: str) -> str:
    """Chuáº©n hoÃ¡ tÃªn chá»‰ sá»‘ Ä‘á»ƒ query dá»… hÆ¡n."""
    return name.strip().lower().replace(" ", "_")

def save_lab_results_grouped(lab_list, user_id: str, document_date):
    """
    LÆ°u bá»™ xÃ©t nghiá»‡m nguyÃªn váº¹n (grouped) vÃ o collection lab_results_grouped.
    - user_id: mÃ£ ngÆ°á»i dÃ¹ng
    - document_date: datetime object, ngÃ y xÃ©t nghiá»‡m
    - lab_list: list of LabItem (hoáº·c dict tÆ°Æ¡ng tá»±)
    """
    # Chuyá»ƒn lab_list (cÃ³ thá»ƒ lÃ  Pydantic model) thÃ nh list dict
    results = [item.model_dump() if hasattr(item, "model_dump") else item for item in lab_list]

    now = datetime.now()

    doc_ref = db.collection("lab_results_grouped").document(f"{user_id}_{now.strftime('%Y-%m-%d %H:%M:%S')}")
    data = {
        "user_id": user_id,
        "document_date": now,
        "results": results,
    }
    doc_ref.set(data)

def save_medicine_list_grouped(medicine_list, user_id: str, document_date):
    """
    LÆ°u Ä‘Æ¡n thuá»‘c nguyÃªn váº¹n (grouped) vÃ o collection medicine_lists_grouped.
    - user_id: mÃ£ ngÆ°á»i dÃ¹ng
    - document_date: datetime object, ngÃ y cá»§a Ä‘Æ¡n thuá»‘c
    - medicine_list: list of MedicineItem (hoáº·c dict tÆ°Æ¡ng tá»±)
    """
    # Chuyá»ƒn medicine_list (cÃ³ thá»ƒ lÃ  Pydantic model) thÃ nh list dict
    medicines = [item.model_dump() if hasattr(item, "model_dump") else item for item in medicine_list]

    doc_ref = db.collection("medicine_lists_grouped").document(f"{user_id}_{document_date.strftime('%Y%m%d')}")
    data = {
        "user_id": user_id,
        "document_date": document_date,
        "medicines": medicines,
    }
    doc_ref.set(data)

def process_image_pipeline(image_path: str):
    print("ğŸ” Báº¯t Ä‘áº§u OCR...")
    text = image_to_text(image_path)
    print("ğŸ“„ Káº¿t quáº£ OCR:\n", text)

    print("ğŸ“‚ Äang phÃ¢n loáº¡i tÃ i liá»‡u...")
    doc_type = classify_doc_type(text)
    print("ğŸ“Œ Loáº¡i tÃ i liá»‡u:", doc_type)

    item = None
    if doc_type == "Ä‘Æ¡n thuá»‘c":
        item = analyze_medicine_with_knowledge(text)
        print("item", item)
        save_medicine_list_grouped(item.medicines, 'A12345', item.document_date)
    elif doc_type == "káº¿t quáº£ xÃ©t nghiá»‡m":
        item = analyze_lab_with_knowledge(text)
        print('item', item)
        save_lab_results_grouped(item.lab, 'A12345', item.document_date)

    return {
        "doc_type": doc_type,
        "structured_data": item,
        "text": text
    }
